import { google } from '@ai-sdk/google';
import { streamText } from 'ai';

// ðŸš€ FIX FINAL : On active le mode Edge pour garantir un stream non mis en mÃ©moire tampon
export const runtime = 'edge'; 
export const maxDuration = 30;

export async function POST(req) {
  // ... (tout le reste du code reste le mÃªme, y compris la logique d'injection des messages)
  try {
    const { messages, data } = await req.json();

    const contextStock = data?.stockInfo 
      ? `CONTEXTE ACTUEL : Action ${data.stockInfo.symbol} Ã  ${data.stockInfo.price}$.`
      : "Pas d'action spÃ©cifique.";

    const result = await streamText({
      model: google('gemini-1.5-flash'),
      settings: {
        safetySettings: [
          { category: 'HARM_CATEGORY_HATE_SPEECH', threshold: 'BLOCK_NONE' },
          { category: 'HARM_CATEGORY_DANGEROUS_CONTENT', threshold: 'BLOCK_NONE' },
          { category: 'HARM_CATEGORY_HARASSMENT', threshold: 'BLOCK_NONE' },
          { category: 'HARM_CATEGORY_SEXUALLY_EXPLICIT', threshold: 'BLOCK_NONE' },
        ],
      },
      messages: [
        {
          role: 'user',
          content: `Tu es un expert en bourse. ${contextStock}. RÃ©ponds en franÃ§ais.`
        },
        ...messages
      ],
    });

    return result.toDataStreamResponse();

  } catch (error) {
    console.error("ERREUR:", error);
    // On retire le code de debug pour revenir Ã  un serveur propre
    return new Response(JSON.stringify({ error: error.message }), { status: 500 });
  }
}